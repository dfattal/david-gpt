---
title: Leia Image Format (LIF) and Leia Video Format (LVF)
docType: note
url: RAG-RAW-DOCS/Notes/LIF.md
scraped_at: 2025-09-26T19:02:00.193Z
word_count: 1151
extraction_quality: high
updated_at: 2025-09-26T19:02:00.193Z
---


# Leia Image Format (LIF) and Leia Video Format (LVF)

This report provides a comprehensive overview of the Leia Image Format (LIF) and Leia Video Format (LVF), based on information gathered from Confluence pages and the Rovo Chat AI.

## Leia Image Format (LIF)

### Purpose & Overview

Leia Image Format (LIF) is a format designed to enable users to capture, create, and experience immersive 3D imagery across various platforms and devices. It is a container format that stores multiple viewpoints of a scene, each with a high-quality disparity map, which is essential for creating a complete 3D image experience. LIF files can be decomposed into depth layers, each containing an RGB texture and a disparity map, facilitating the view synthesis process.

LIF is primarily used in applications that require depth-rich visuals, such as XR (Extended Reality) environments. It supports rendering in 2D, 3D stereo, and 3D interactive modes, making it versatile for different types of displays and devices.

### Technical Structure

*   **Multi-view Support**: LIF can store one, two, or possibly multiple view points of a scene.
*   **Disparity Maps**: Each view includes a high-quality disparity (depth) map.
*   **Layered Depth**: Views can be decomposed into depth layers, each with its own RGB texture and disparity map, facilitating advanced view synthesis (e.g., for XR/AR applications).
*   **Completeness**: Every view/layer must have both an RGB texture and a disparity map.

### Creation & Processing

*   **Sources**: LIF files can be created from various sources, including Immersity AI (web/mobile), Immersity SDK (Windows/Android), Leia Camera SDK, and 3rd-party stereo images (L-R, SBS).
*   **Processing**: Depending on the source, additional processing may be needed to generate or improve disparity maps and decompose into depth layers.

### Consumption & Compatibility

*   **Platforms**: LIF images can be rendered in 2D, 2D interactive, 3D stereo, and 3D interactive (XR) modes across browsers, LeiaSR devices, and XR devices.
*   **Messaging**: Only certain platforms (e.g., Email, Discord) preserve LIF metadata for 3D display; others strip metadata unless files are zipped.
*   **Versioning**: LIF versions below 5.3 may be treated as 2D by some apps.

### Developer Support

*   **SDKs**: Android and Python SDKs are available for encoding/decoding LIF, supporting stereo (2x1), quad (2x2), and legacy Leia photo formats.
*   **Open Source**: Libraries and documentation are available on GitHub.

### Advanced Features (LIF 5.0+)

Next-gen LIF aims to record a complete set of camera intrinsics and extrinsics linked to each image view and facilitate the process of generating arbitrary new view points inside the camera space described by the file.

### LIF 5.3 Specification (JSON)

```json
{
  "encoder": "5.3.0 (python)",
  "baseline_mm": 45,
  "views": [
    {
      "width_px": 3456,
      "height_px": 2345,
      "focal_px": 1234,
      "frustum_skew": {
        "x": 0.0,
        "y": 0.0
      },
      "position": {
        "x": 0.0,
        "y": 0.0,
        "z": 0.0
      },
      "rotation": {
        "rotation_slant": {
          "x": 0.0,
          "y": 0.0
        },
        "roll_degrees": 0.0
      },
      "lens_focus_inv_z_dist": null,
      "image": {
        "blob_id": -1
      },
      "inv_z_map": {
        "blob_id": 1000001,
        "min": 0.123,
        "max": 0.012,
        "software": "disparity estimator ver 1.2345"
      },
      "layers_top_to_bottom": [
        {
          "width_px": 3456,
          "height_px": 2345,
          "focal_px": 456,
          "software": "ldl generator ver 2.3456",
          "image": {
            "blob_id": -1,
            "outpainting_blob_id": 1000002
          },
          "inv_z_map": {
            "blob_id": 1000001,
            "outpainting_blob_id": 1000003,
            "min": 0.123,
            "max": 0.012,
            "software": "disparity estimator ver 1.2345"
          },
          "mask": {
            "blob_id": 1000004,
            "outpainting_blob_id": 1000005
          }
        }
      ]
    }
  ],
  "stereo_render_data": {
    "baseline": 1.0,
    "inv_convergence_distance": 0.1122,
    "focal_px": 1234,
    "width_px": 3456,
    "height_px": 2345,
    "frustum_skew": {
      "x": 0.0,
      "y": 0.0
    },
    "position": {
      "x": 0.0,
      "y": 0.0,
      "z": 0.0
    },
    "rotation": {
      "rotation_slant": {
        "x": 0.0,
        "y": 0.0
      },
      "roll_degrees": 0.0
    }
  },
  "animations": [
    {
      "type": "harmonic",
      "name": "Animation #1",
      "duration_sec": 10.0,
      "ping_pong_loop": false,
      "data": {
        "baseline": {
          "amplitude": 0.0,
          "bias": 1.0
        },
        "inv_convergence_distance": {
          "amplitude": 1.0,
          "phase": 0.0
        },
        "focal_px": {
          "value": 1234
        },
        "width_px": 3456,
        "height_px": 2345,
        "frustum_skew": {
          "x": {
            "amplitude": 1.0,
            "phase": 0.0
          },
          "y": {
            "amplitude": 1.0,
            "phase": 0.0
          }
        },
        "position": {
          "x": {
            "amplitude": 1.0,
            "phase": 0.0
          },
          "y": {
            "amplitude": 1.0,
            "phase": 0.0
          },
          "z": {
            "amplitude": 0.5,
            "phase": 0.0,
            "bias": 0.5
          }
        },
        "rotation": {
          "rotation_slant": {
            "x": {
              "amplitude": 1.0,
              "phase": 0.0
            },
            "y": {
              "amplitude": 1.0,
              "phase": 0.0
            }
          },
          "roll_degrees": {
            "amplitude": 1.0,
            "phase": 0.0
          }
        }
      }
    },
    {
      "type": "keyframes",
      "name": "Animation #2",
      "duration_sec": 10.0,
      "ping_pong_loop": false,
      "data": {
        "baseline": {
          "interpolation": {
            "algorithm": "linear"
          },
          "frames": [
            {
              "t_ms": 0.0,
              "value": 1.0
            },
            {
              "t_ms": 5000.0,
              "value": 2.0
            },
            {
              "t_ms": 10000.0,
              "value": 1.0
            }
          ]
        },
        "inv_convergence_distance": {
          "interpolation": {
            "algorithm": "linear"
          },
          "frames": [
            {
              "t_ms": 0.0,
              "value": 0.1234
            },
            {
              "t_ms": 10000.0,
              "value": 0.2
            }
          ]
        },
        "focal_px": {
          "interpolation": {
            "algorithm": "quadratic-bezier"
          },
          "frames": [
            {
              "t_ms": 0.0,
              "value": 1234
            },
            {
              "t_ms": 5000.0,
              "value": 2345
            },
            {
              "t_ms": 10000.0,
              "value": 455
            }
          ]
        },
        "width_px": 3456,
        "height_px": 2345,
        "frustum_skew": {
          "interpolation": {
            "algorithm": "catmull-rom",
            "params": {
              "alpha": 0.5
            }
          },
          "frames": [
            {
              "t_ms": 0.0,
              "value": {
                "x": 0.0,
                "y": 0.0
              }
            },
            {
              "t_ms": 2500.0,
              "value": {
                "x": 0.5,
                "y": 0.0
              }
            },
            {
              "t_ms": 6700.0,
              "value": {
                "x": 0.0,
                "y": -0.5
              }
            },
            {
              "t_ms": 10000.0,
              "value": {
                "x": 0.0,
                "y": 0.0
              }
            }
          ]
        },
        "position": {
          "interpolation": {
            "algorithm": "catmull-rom",
            "params": {
              "alpha": 0.5
            }
          },
          "frames": [
            {
              "t_ms": 0.0,
              "value": {
                "x": 0.0,
                "y": 0.0,
                "z": 0.0
              }
            },
            {
              "t_ms": 2900.0,
              "value": {
                "x": 0.1,
                "y": 0.0,
                "z": 0.5
              }
            },
            {
              "t_ms": 3800.0,
              "value": {
                "x": 0.0,
                "y": 0.1,
                "z": 0.3
              }
            },
            {
              "t_ms": 10000.0,
              "value": {
                "x": 0.1,
                "y": 0.0,
                "z": 0.0
              }
            }
          ]
        },
        "rotation": {
          "interpolation": {
            "algorithm": "linear"
          },
          "frames": [
            {
              "t_ms": 0.0,
              "value": {
                "rotation_slant": {
                  "x": 0.0,
                  "y": 0.0
                },
                "roll_degrees": 0.0
              }
            },
            {
              "t_ms": 10000.0,
              "value": {
                "rotation_slant": {
                  "x": 0.0,
                  "y": 0.0
                },
                "roll_degrees": 45.0
              }
            }
          ]
        }
      }
    }
  ]
}
```

## Leia Video Format (LVF)

### Purpose & Overview

LVF is Leia’s proprietary video format for 3D video, designed to maximize compatibility with both Leia 3D displays and legacy 2D devices. It replaces older formats like the Hydrogen One’s “4V videos” and standardizes the 3D video experience to match LIF for photos.

### Technical Structure

*   **Dual Streams**: LVF encodes two video streams: a 2D stream (left view) for legacy/third-party apps and a second 2D stream (right view) for Leia apps, enabling full 3D playback.
*   **Legacy Compatibility**: 2D apps decode only the left stream, showing the video in 2D; Leia apps decode both for 3D.
*   **No More 2x1**: Future Leia devices will not support 2x1 recording; LVF is the exclusive format for 3D video capture.

### Metadata & Reconvergence

*   **Convergence Handling**: LVFs are stored without hard-coded convergence. Metadata can specify ‘auto’ or manual convergence values, and advanced metadata can store arrays of manual values for keyframes.
*   **On-the-fly Reconvergence**: Playback apps like LeiaPlayer reconverge LVFs dynamically based on metadata.
*   **Editing**: LeiaPlayer allows setting manual convergence for the entire LVF or reverting to auto-convergence.
